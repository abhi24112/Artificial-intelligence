{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear regression model attempts to explain the relationship between a dependent (output variables) variable and one or more independent (predictor variable) variables using a straight line.\n",
    "\n",
    "This straight line is represented using the following formula:\n",
    "\n",
    "**y = mx +c**\n",
    "\n",
    "Where,\n",
    "y: dependent variable\n",
    "\n",
    "x: independent variable\n",
    "\n",
    "m: Slope of the line (For a unit increase in the quantity of X,Y increases by m.1 = m units.)\n",
    "\n",
    "c: y intercept (The value of Y is c when the value of X is 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\">\n",
    "The first step in finding a linear regression equation is to determine if there is a relationship between the two variables. We can do this by using the Correlation coefficient and scatter plot. When a correlation coefficient shows that data is likely to be able to predict future outcomes and a scatter plot of the data appears to form a straight line, we can use simple linear regression to find a predictive function. Let us consider an example.\n",
    "<img src=\"2.png\">\n",
    "From the scatter plot we can see there is a linear relationship between Sales and marketing spent. The next step is to find a straight line between Sales and Marketing that explain the relationship between them. But there can be multiple lines that can pass through these points.\n",
    "<img src=\"3.png\">\n",
    "So how do we know which of these lines is the best fit line? That’s the problem that we will solve in this article. For this, we will first look at the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost is the error in our predicted value. We will use the Mean Squared Error function to calculate the cost.\n",
    "<img src=\"4.png\">\n",
    "<img src=\"5.png\">\n",
    "Our goal is to minimize the cost as much as possible in order to find the best fit line. We are not going to try all the permutation and combination of m and c (inefficient way) to find the best-fit line. For that, we will use Gradient Descent Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent is an algorithm that finds the best-fit line for a given training dataset in a smaller number of iterations.\n",
    "\n",
    "If we plot m and c against MSE, it will acquire a bowl shape (As shown in the diagram below)\n",
    "<img src=\"6.png\">\n",
    "For some combination of m and c, we will get the least Error (MSE). That combination of m and c will give us our best fit line.\n",
    "\n",
    "The algorithm starts with some value of m and c (usually starts with m=0, c=0). We calculate MSE (cost) at point m=0, c=0. Let say the MSE (cost) at m=0, c=0 is 100. Then we reduce the value of m and c by some amount (Learning Step). We will notice a decrease in MSE (cost). We will continue doing the same until our loss function is a very small value or ideally 0 (which means 0 error or 100% accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let m = 0 and c = 0. Let L be our learning rate. It could be a small value like 0.01 for good accuracy.\n",
    "\n",
    "Learning rate gives the rate of speed where the gradient moves during gradient descent. Setting it too high would make your path instable, too low would make convergence slow. Put it to zero means your model isn’t learning anything from the gradients.\n",
    "\n",
    " \n",
    "\n",
    "2. Calculate the partial derivative of the Cost function with respect to m. Let partial derivative of the Cost function with respect to m be Dm (With little change in m how much Cost function changes).\n",
    "<img src=\"7.png\">\n",
    "Similarly, let’s find the partial derivative with respect to c. Let partial derivative of the Cost function with respect to c be Dc (With little change in c how much Cost function changes).\n",
    "<img src=\"8.png\">\n",
    "3. Now update the current values of m and c using the following equation:\n",
    "<img src=\"9.png\">\n",
    "4. We will repeat this process until our Cost function is very small (ideally 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"10.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12.0, 9.0)\n",
    "\n",
    "# Preprocessing Input data\n",
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0]\n",
    "Y = data.iloc[:, 1]\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "m = 0\n",
    "c = 0\n",
    "L = 0.0001  # The learning Rate\n",
    "epochs = 1000  # The number of iterations to perform gradient descent\n",
    "n = float(len(X)) # Number of elements in X\n",
    "\n",
    "# Performing Gradient Descent \n",
    "for i in range(epochs): \n",
    "    Y_pred = m*X + c  # The current predicted value of Y\n",
    "    D_m = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n",
    "    D_c = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n",
    "    m = m - L * D_m  # Update m\n",
    "    c = c - L * D_c  # Update c\n",
    "    \n",
    "print (m, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "Y_pred = m*X + c\n",
    "plt.scatter(X, Y) \n",
    "plt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='red')  # regression line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
